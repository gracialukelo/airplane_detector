{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN4WF8qaVqGfti6K1HpnoVp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gracialukelo/airplane_detector/blob/main/LLM_Begins.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssFKTDJzaYEN",
        "outputId": "cb821827-cacd-4d28-84e5-f277996af779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello World!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The requirement for this code:\n",
        "# !pip list (check if you already have everthing you need)\n",
        "# !pip install transformers\n",
        "# !pip install transformers bitsandbytes>=0.39.0 -q\n",
        "# !pip install langchain, accelerate"
      ],
      "metadata": {
        "id": "jTFZ45h9ag7C"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "eBeoREDc4Zvk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text generieren**"
      ],
      "metadata": {
        "id": "UOI7e70QtcaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zunächst sicherstellen, dass transformers installiert ist\n",
        "# Dies kannst du in einer Python-Umgebung machen, z.B. durch `!pip install transformers`\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# Pipeline für Textgenerierung mit GPT-2\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "# Eingabetext, der als Startpunkt für die Generierung verwendet wird\n",
        "prompt_text = \"Heute lernen wir, wie man künstliche Intelligenz in der Bildverarbeitung einsetzt.\"\n",
        "\n",
        "# Text generieren\n",
        "generated_text = generator(\n",
        "    prompt_text,\n",
        "    max_length=100,\n",
        "    num_return_sequences=1,\n",
        "    truncation=True,\n",
        "    temperature=1,      # kontrolliert die Kreativität; niedriger bedeutet kohärenter\n",
        "    top_k=50,             # beschränkt die Auswahl der nächsten Token auf die Top 50\n",
        "    top_p=0.9             # fokussiert auf wahrscheinlichste Wörter\n",
        "    )\n",
        "\n",
        "# Ausgabe anzeigen\n",
        "print(f\"\\n{generated_text[0]['generated_text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdrOI9OJ59gO",
        "outputId": "786e796d-af55-4d9f-a02c-b330a3f8c14e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Heute lernen wir, wie man künstliche Intelligenz in der Bildverarbeitung einsetzt.\n",
            "\n",
            "Hans Lüttersbücke und Welt als Welt nicht sind schlässlich, das den eigen Natur von Nachrichten auf einen Migranten des das Jahrhunderts.\n",
            "\n",
            "Aus dem Einheit sie eins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frage beantworten**"
      ],
      "metadata": {
        "id": "a6ypefqMvrvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline für Fragen und Antworten\n",
        "qa_pipeline = pipeline(\"question-answering\")\n",
        "\n",
        "# Kontext, aus dem die Antwort entnommen werden soll\n",
        "context = \"\"\"\n",
        "Künstliche Intelligenz (KI) bezieht sich auf die Fähigkeit von Maschinen, Aufgaben auszuführen, die normalerweise menschliche Intelligenz erfordern.\n",
        "Dazu gehören das Erkennen von Sprache, das Treffen von Entscheidungen, das Erkennen von Objekten und vieles mehr.\n",
        "KI hat viele Anwendungen in Bereichen wie Medizin, Finanzen, und Bildverarbeitung.\n",
        "\"\"\"\n",
        "\n",
        "# Die Frage, die beantwortet werden soll\n",
        "question = \"Was ist künstliche Intelligenz und in welcher Bereich wird es eingesetzt?\"\n",
        "\n",
        "# Die Antwort generieren lassen\n",
        "answer = qa_pipeline(question=question, context=context)\n",
        "\n",
        "# Antwort anzeigen\n",
        "print(\"Antwort:\", answer['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjKUv2WfkC-A",
        "outputId": "cb83a166-390e-46d8-d493-a2a4c02a49ab"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antwort: Künstliche Intelligenz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V3dcowpQvqU9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FSh9Vq_mko9H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}